# ShelfOps Model Readiness Matrix

_Last updated: February 15, 2026_

This is the source-of-truth status artifact for model/data readiness.

Status definitions:

- `ready_now`: trained/evaluated with current dataset
- `partial`: functional logic, pending production telemetry calibration
- `blocked`: architecture complete, awaiting labeled operational data

| model_id | code_path | business_use | data_required | data_available_now | status | next_data_gate | next_implementation_step | how_to_discuss_publicly |
|---|---|---|---|---|---|---|---|---|
| demand_forecast | `backend/ml/train.py`, `backend/ml/predict.py` | Baseline demand forecasting | Store/product/date demand history + calendar features | Favorita/Walmart/Rossmann + seed datasets available | `ready_now` | Tenant onboarding telemetry depth + production calibration | Run baseline + targeted sweep protocol, keep champion/challenger tracking | Trained/evaluated with current public datasets; production tuning continues as tenant data expands. |
| backtest_arena | `backend/ml/backtest.py`, `backend/ml/arena.py` | Model comparison and walk-forward validation | Forecasts + actuals + model registry tables | Available via current ML Ops schema/test fixtures | `ready_now` | Stable Postgres CI + contract freeze | Continue daily/weekly backtest workflow and promotion gates | Backtesting and model lifecycle tooling are operational with current data scope. |
| anomaly_detection | `backend/ml/anomaly.py` | Detect demand/inventory anomalies | Forecast + inventory + transaction behavior with outcomes labels | Partial synthetic + test data; limited production labels | `partial` | Labeled true/false positive outcomes over sustained period | Calibrate thresholds and retraining triggers from real outcomes | Functional logic exists; calibration depends on real telemetry. |
| ghost_stock | `backend/ml/ghost_stock.py` | Phantom inventory detection | Cycle count truth, shelf availability, discrepancy labels | No robust labeled production corpus in repo | `blocked` | Partner-labeled inventory discrepancy dataset | Build supervised validation pipeline and precision/recall targets | Architecture is implemented; production-grade calibration needs labeled partner data. |
| segmentation | `backend/ml/segmentation.py` | Store/category segmentation for planning | Multi-store behavior with stable cluster features | Partial (schema + seed support exists) | `partial` | Real store profile and performance history | Validate segmentation stability and business impact per segment | Segmentation support is present; full tuning awaits richer operational data. |
| explainability | `backend/ml/explain.py` | Feature importance and explainability export | Trained model artifacts + feature matrix | Available with current forecast training artifacts | `ready_now` | Cross-dataset consistency checks | Integrate explanation summaries into model card workflow | Explainability pipeline works on current trained artifacts. |
| validation_schemas | `backend/ml/validate.py` | Data quality gates for training/inference | Structured input DataFrames | Available in pipeline/tests | `ready_now` | Add enterprise ingestion schema variants | Expand checks for additional real-world connectors | Validation gates are active and testable now. |
| canonical_data_contracts | `backend/ml/data_contracts.py` | Normalize heterogeneous datasets into one training contract | Source dataset-specific transaction schemas + required canonical fields | Implemented for Favorita/Walmart/Rossmann/seed with tests | `ready_now` | Add coverage for additional public/private datasets | Extend loader registry and cross-domain schema checks | Canonical training-data normalization is implemented; new dataset adapters are incremental work. |
| contract_profiles | `backend/ml/contract_profiles.py` | Versioned tenant/source contract loading and schema governance | YAML contract profiles with mapping and DQ thresholds | Implemented with parser validation tests | `ready_now` | Expand profile coverage for additional tenant archetypes | Add signed-change review workflow for contract updates | Contract profile framework is implemented and usable for onboarding. |
| contract_mapper | `backend/ml/contract_mapper.py` | Profile-driven mapping + strict onboarding quality gates | Raw source payloads + tenant contract profile | Implemented with mapper and validator tests | `ready_now` | Add advanced unit/timezone normalization variants | Extend mapper for additional enterprise payload edge cases | Contract-driven canonical mapping and validation are operational for current onboarding scope. |
| business_metrics | `backend/ml/business_metrics.py` | Translate forecast outputs into business-impact metrics | Predicted vs actual quantities plus cost proxies | Implemented overstock-dollar calculation with tests | `partial` | Broader production unit-cost coverage and outcome tracking | Integrate business metrics into continuous backtest/reporting pipeline | Business-metric utilities are implemented; richer calibration depends on production telemetry depth. |
| feature_pipeline | `backend/ml/features.py` | Feature engineering for forecasting/training pipelines | Raw sales/calendar/store/product signals | Available from current Favorita + pipeline inputs | `ready_now` | Cross-dataset feature parity checks | Harden feature-contract tests across additional datasets | Feature pipeline is implemented and usable now; extensions depend on added datasets. |
| experiment_tracking | `backend/ml/experiment.py` | Track params/metrics/model metadata | Model run metadata + metrics | Available in current ML Ops flow | `ready_now` | Postgres parity for experiment writes | Standardize experiment naming and sweep reports | Experiment tracking is operational for current tuning phase. |
| feedback_loop | `backend/ml/feedback_loop.py` | Human-in-the-loop feedback ingestion | Outcome/decision feedback history | Partial outcome data in current environment | `partial` | Sustained real user decision/outcome capture | Add closed-loop retraining triggers from live feedback | Feedback mechanism exists; full value depends on live usage volume. |
| alert_outcomes | `backend/ml/alert_outcomes.py` | Outcome capture + status mapping | Alert/anomaly outcomes | Available and tested in API contract tests | `ready_now` | Broader production outcome volume | Expand analytics for precision/ROI over time | Outcome logging is functional today. |
| charts_reporting | `backend/ml/charts.py` | ML reporting visualization prep | Backtest/forecast metric series | Available from current ML outputs | `ready_now` | Add production trend baselines | Standardize chart outputs in run artifacts | Reporting utilities are ready with current outputs. |
| category_training | `backend/scripts/train_category_models.py` | Category-specific forecast models | Sufficient per-category demand history | Partial (depends on category depth beyond baseline) | `partial` | Category-level minimum-history thresholds met | Run controlled category-vs-global comparisons | Category models are implementable; rollout depends on category data depth. |
| training_orchestration | `backend/scripts/run_training.py` | Repeatable training entrypoint | Training dataset + configs | Available for Favorita baseline | `ready_now` | Cross-dataset run compatibility | Keep runbook-driven execution and model cards | Training orchestration is operational for baseline phase. |
| enterprise_seed_validation | `backend/scripts/validate_enterprise_seed.py` | Integration-data readiness gate | Seeded EDI/SFTP/Kafka artifact set | Available via synthetic generators | `ready_now` | CI-required status checks on main | Keep strict validation in CI and release checklist | Enterprise integration validation tooling is active; this is not equivalent to live enterprise onboarding. |
| ml_ops_api_surface | `backend/api/v1/routers/ml_ops.py`, `backend/api/v1/routers/models.py` | Expose model health/backtest data to UI | Stable response contracts + registry data | Available; prefix consistency cleanup pending | `partial` | Prefix consolidation and contract freeze | Deprecate duplicate paths and finalize canonical API | Model APIs are functional but still being normalized. |

## Communication Policy

- `ready_now`: "trained/evaluated with current dataset."
- `partial`: "functional logic, pending production telemetry calibration."
- `blocked`: "architecture complete, awaiting labeled operational data."

Note: `backend/ml/__init__.py` is a package marker and is intentionally excluded from model readiness tracking.
